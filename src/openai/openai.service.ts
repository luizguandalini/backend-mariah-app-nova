import { Injectable, Logger, OnModuleInit } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository } from 'typeorm';
import { SystemConfig } from '../config/entities/system-config.entity';
import {
  normalizeForMatch,
  extractKeywords,
  findBestMatch,
} from '../common/utils/text-normalizer.util';

/**
 * Status codes da API OpenAI e seus significados:
 * 
 * 200 - Sucesso
 * 400 - Bad Request (prompt inv√°lido, imagem muito grande, etc)
 * 401 - Unauthorized (API key inv√°lida ou expirada)
 * 403 - Forbidden (sem permiss√£o para usar o modelo)
 * 404 - Not Found (modelo n√£o existe)
 * 429 - Rate Limit Exceeded (muitas requisi√ß√µes)
 * 500 - Internal Server Error (erro no lado da OpenAI)
 * 502 - Bad Gateway
 * 503 - Service Unavailable (OpenAI sobrecarregada)
 * 504 - Gateway Timeout
 */

interface OpenAIError {
  status: number;
  message: string;
  type: string;
  retryable: boolean;
  retryAfter?: number;
  criticalError?: boolean; // true = deve pausar a fila (401/403/404)
}

interface AnalysisResult {
  success: boolean;
  content?: string;
  error?: OpenAIError;
  tokensUsed?: number;
  criticalError?: boolean; // Propagar para o caller
}

@Injectable()
export class OpenAIService implements OnModuleInit {
  private readonly logger = new Logger(OpenAIService.name);
  private apiKey: string | null = null;
  private model: string = 'gpt-4o';
  private maxTokens: number = 150;
  private rateLimitRpm: number = 20;
  private rateLimitDelayMs: number = 3000;
  private lastRequestTime: number = 0;

  constructor(
    @InjectRepository(SystemConfig)
    private readonly configRepository: Repository<SystemConfig>,
  ) {}

  async onModuleInit() {
    await this.loadConfig();
  }

  /**
   * Carrega configura√ß√µes do banco de dados
   */
  async loadConfig(): Promise<void> {
    try {
      const configs = await this.configRepository.find();
      const configMap = new Map(configs.map((c) => [c.key, c.value]));

      this.apiKey = configMap.get('openai_api_key') || null;
      this.model = configMap.get('openai_model') || 'gpt-4o';
      this.maxTokens = parseInt(configMap.get('openai_max_tokens') || '70', 10);
      this.rateLimitRpm = parseInt(configMap.get('rate_limit_rpm') || '20', 10);
      this.rateLimitDelayMs = parseInt(configMap.get('rate_limit_delay_ms') || '3000', 10);

      this.logger.log(`Configura√ß√µes OpenAI carregadas: model=${this.model}, rpm=${this.rateLimitRpm}`);
    } catch (error) {
      this.logger.error('Erro ao carregar configura√ß√µes OpenAI', error);
    }
  }

  /**
   * Verifica se o servi√ßo est√° configurado e pronto
   */
  isConfigured(): boolean {
    return !!this.apiKey && this.apiKey.length > 10;
  }

  /**
   * Atualiza a API Key
   */
  async updateApiKey(apiKey: string, userId: string): Promise<void> {
    await this.configRepository.upsert(
      {
        key: 'openai_api_key',
        value: apiKey,
        isEncrypted: false, // TODO: implementar criptografia
        updatedById: userId,
      },
      ['key'],
    );
    this.apiKey = apiKey;
    this.logger.log('API Key OpenAI atualizada');
  }

  /**
   * Testa a conex√£o com a API OpenAI
   */
  async testConnection(): Promise<{ success: boolean; message: string }> {
    if (!this.isConfigured()) {
      return { success: false, message: 'API Key n√£o configurada' };
    }

    try {
      const response = await fetch('https://api.openai.com/v1/models', {
        method: 'GET',
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
        },
      });

      if (response.ok) {
        return { success: true, message: 'Conex√£o estabelecida com sucesso' };
      } else {
        const error = await response.json();
        return {
          success: false,
          message: error.error?.message || `Erro ${response.status}`,
        };
      }
    } catch (error) {
      return {
        success: false,
        message: `Erro de conex√£o: ${error.message}`,
      };
    }
  }

  /**
   * Aguarda o rate limit antes de fazer requisi√ß√£o
   */
  private async waitForRateLimit(): Promise<void> {
    const now = Date.now();
    const timeSinceLastRequest = now - this.lastRequestTime;
    const minDelay = this.rateLimitDelayMs;

    if (timeSinceLastRequest < minDelay) {
      const waitTime = minDelay - timeSinceLastRequest;
      this.logger.debug(`Aguardando ${waitTime}ms para rate limit`);
      await new Promise((resolve) => setTimeout(resolve, waitTime));
    }

    this.lastRequestTime = Date.now();
  }

  /**
   * Analisa uma imagem com um prompt espec√≠fico
   * @param imageUrl URL pr√©-assinada do S3 ou base64
   * @param prompt Prompt para an√°lise
   * @param retryCount Contagem de retries (interno)
   */
  async analyzeImage(
    imageUrl: string,
    prompt: string,
    retryCount: number = 0,
  ): Promise<AnalysisResult> {
    if (!this.isConfigured()) {
      return {
        success: false,
        error: {
          status: 401,
          message: 'API Key n√£o configurada',
          type: 'configuration_error',
          retryable: false,
        },
      };
    }

    await this.waitForRateLimit();

    try {
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.model,
          max_tokens: this.maxTokens,
          messages: [
            {
              role: 'user',
              content: [
                {
                  type: 'text',
                  text: prompt,
                },
                {
                  type: 'image_url',
                  image_url: {
                    url: imageUrl,
                    detail: 'low', // Usar 'low' para economizar tokens
                  },
                },
              ],
            },
          ],
        }),
      });

      // Tratar resposta
      if (response.ok) {
        const data = await response.json();
        const content = data.choices?.[0]?.message?.content || '';
        const tokensUsed = data.usage?.total_tokens || 0;

        this.logger.debug(`An√°lise conclu√≠da: ${content.substring(0, 100)}...`);

        return {
          success: true,
          content: content.trim(),
          tokensUsed,
        };
      }

      // Tratar erros espec√≠ficos
      const errorData = await response.json().catch(() => ({}));
      const error = this.handleApiError(response.status, errorData);

      // Retry autom√°tico para erros retryable
      if (error.retryable && retryCount < 3) {
        const waitTime = error.retryAfter || (retryCount + 1) * 5000;
        this.logger.warn(
          `Erro ${error.status} (${error.type}), aguardando ${waitTime}ms antes de retry ${retryCount + 1}/3`,
        );
        await new Promise((resolve) => setTimeout(resolve, waitTime));
        return this.analyzeImage(imageUrl, prompt, retryCount + 1);
      }

      // Retornar com flag de erro cr√≠tico para pausar fila
      return { 
        success: false, 
        error,
        criticalError: error.criticalError || false,
      };
    } catch (error) {
      this.logger.error('Erro ao analisar imagem:', error);
      return {
        success: false,
        error: {
          status: 0,
          message: error.message || 'Erro de conex√£o',
          type: 'network_error',
          retryable: true,
        },
      };
    }
  }

  /**
   * Trata erros da API OpenAI com logs detalhados
   * 
   * A√á√ïES POR STATUS CODE:
   * 
   * 400 - BAD REQUEST
   *   - Causa: Prompt inv√°lido, imagem muito grande ou formato incorreto
   *   - A√ß√£o: N√ÉO faz retry, marca imagem como erro, log de erro
   *   - Impacto: Imagem n√£o ser√° analisada, precisa corre√ß√£o manual
   * 
   * 401 - UNAUTHORIZED
   *   - Causa: API Key inv√°lida, expirada ou revogada
   *   - A√ß√£o: N√ÉO faz retry, PARA todo processamento da fila
   *   - Impacto: CR√çTICO - Admin precisa atualizar API Key
   * 
   * 403 - FORBIDDEN
   *   - Causa: Conta sem permiss√£o para usar o modelo (ex: GPT-4)
   *   - A√ß√£o: N√ÉO faz retry, log de erro cr√≠tico
   *   - Impacto: CR√çTICO - Precisa fazer upgrade da conta OpenAI ou trocar modelo
   * 
   * 404 - NOT FOUND
   *   - Causa: Modelo especificado n√£o existe (ex: typo no nome)
   *   - A√ß√£o: N√ÉO faz retry, log de erro de configura√ß√£o
   *   - Impacto: Admin precisa corrigir o nome do modelo nas configura√ß√µes
   * 
   * 429 - RATE LIMIT
   *   - Causa: Muitas requisi√ß√µes por minuto ou quota mensal excedida
   *   - A√ß√£o: FAZ retry ap√≥s aguardar tempo indicado pelo header retry-after
   *   - Impacto: Tempor√°rio - processamento continua ap√≥s espera
   * 
   * 500/502/503/504 - SERVER ERROR
   *   - Causa: Problema no lado da OpenAI (instabilidade, manuten√ß√£o)
   *   - A√ß√£o: FAZ retry ap√≥s 5 segundos (at√© 3 tentativas)
   *   - Impacto: Tempor√°rio - geralmente resolve sozinho
   */
  private handleApiError(status: number, data: any): OpenAIError {
    const message = data.error?.message || `Erro HTTP ${status}`;
    const type = data.error?.type || 'unknown_error';

    switch (status) {
      case 400:
        this.logger.error(
          `‚ùå [400 BAD_REQUEST] Requisi√ß√£o inv√°lida para OpenAI\n` +
          `   üìã Motivo: ${message}\n` +
          `   üîß A√ß√£o: Imagem ser√° marcada como erro. Verifique formato/tamanho da imagem ou prompt.`
        );
        return {
          status,
          message,
          type: 'bad_request',
          retryable: false,
        };

      case 401:
        this.logger.error(
          `üö® [401 UNAUTHORIZED] API Key inv√°lida ou expirada!\n` +
          `   üìã Motivo: ${message}\n` +
          `   üîß A√ß√£o: PROCESSAMENTO PARADO. Admin deve atualizar a API Key em Configura√ß√µes IA.\n` +
          `   ‚ö†Ô∏è  CR√çTICO: Todas as an√°lises falhar√£o at√© corre√ß√£o!`
        );
        return {
          status,
          message: 'API Key inv√°lida ou expirada',
          type: 'authentication_error',
          retryable: false,
          criticalError: true, // PAUSAR FILA
        };

      case 403:
        this.logger.error(
          `üö´ [403 FORBIDDEN] Sem permiss√£o para usar modelo ${this.model}\n` +
          `   üìã Motivo: ${message}\n` +
          `   üîß A√ß√£o: Verificar se a conta OpenAI tem acesso ao modelo ${this.model}.\n` +
          `   üí° Dica: Pode ser necess√°rio upgrade para GPT-4 ou escolher modelo diferente.`
        );
        return {
          status,
          message: 'Sem permiss√£o para usar este modelo',
          type: 'permission_error',
          retryable: false,
          criticalError: true, // PAUSAR FILA
        };

      case 404:
        this.logger.error(
          `üîç [404 NOT_FOUND] Modelo "${this.model}" n√£o encontrado\n` +
          `   üìã Motivo: ${message}\n` +
          `   üîß A√ß√£o: Admin deve corrigir o nome do modelo nas configura√ß√µes do sistema.\n` +
          `   üí° Modelos v√°lidos: gpt-4o, gpt-4-turbo, gpt-4-vision-preview, gpt-3.5-turbo`
        );
        return {
          status,
          message: 'Modelo n√£o encontrado',
          type: 'not_found',
          retryable: false,
          criticalError: true, // PAUSAR FILA
        };

      case 429:
        // IMPORTANTE: Distinguir entre RATE LIMIT (muitas requisi√ß√µes) e QUOTA EXCEEDED (sem cr√©ditos)
        // A mensagem "exceeded your current quota" indica FALTA DE CR√âDITOS, n√£o velocidade!
        const isQuotaExceeded = message.toLowerCase().includes('exceeded your current quota') ||
                                message.toLowerCase().includes('billing') ||
                                message.toLowerCase().includes('plan');
        
        if (isQuotaExceeded) {
          // QUOTA EXCEEDED = SEM CR√âDITOS NA CONTA OPENAI
          this.logger.error(
            `\n` +
            `‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n` +
            `‚ïë  üí≥ [429 QUOTA_EXCEEDED] SEM CR√âDITOS NA CONTA OPENAI               ‚ïë\n` +
            `‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n` +
            `‚ïë  ‚ùå PROBLEMA: A conta OpenAI n√£o tem saldo/cr√©ditos suficientes.    ‚ïë\n` +
            `‚ïë                                                                      ‚ïë\n` +
            `‚ïë  üîß COMO RESOLVER:                                                   ‚ïë\n` +
            `‚ïë     1. Acesse: https://platform.openai.com/account/billing          ‚ïë\n` +
            `‚ïë     2. Adicione cr√©ditos ou configure m√©todo de pagamento           ‚ïë\n` +
            `‚ïë     3. Verifique se h√° limite de gastos (Usage limits)              ‚ïë\n` +
            `‚ïë                                                                      ‚ïë\n` +
            `‚ïë  ‚ö†Ô∏è  A FILA FOI PAUSADA. Retry N√ÉO vai resolver este problema.      ‚ïë\n` +
            `‚ïë     O sistema N√ÉO tentar√° novamente automaticamente.                ‚ïë\n` +
            `‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n`
          );
          return {
            status,
            message: 'Conta OpenAI sem cr√©ditos. Adicione saldo em platform.openai.com/account/billing',
            type: 'quota_exceeded',
            retryable: false, // N√ÉO FAZER RETRY - n√£o vai resolver!
            criticalError: true, // PAUSAR FILA IMEDIATAMENTE
          };
        }
        
        // RATE LIMIT REAL = Muitas requisi√ß√µes por segundo/minuto
        const retryAfterHeader = data.error?.retry_after;
        const retryAfter = retryAfterHeader 
          ? parseInt(retryAfterHeader, 10) * 1000 
          : 60000; // Default: 60 segundos
        
        this.logger.warn(
          `‚è≥ [429 RATE_LIMIT] Limite de velocidade de requisi√ß√µes\n` +
          `   üìã Motivo: Muitas requisi√ß√µes em pouco tempo\n` +
          `   üîß A√ß√£o: Aguardando ${retryAfter / 1000}s antes de tentar novamente.\n` +
          `   üí° Dica: Isso √© normal e ser√° resolvido automaticamente.`
        );
        return {
          status,
          message: 'Limite de velocidade excedido, aguardando...',
          type: 'rate_limit_error',
          retryable: true,
          retryAfter,
        };

      case 500:
        this.logger.warn(
          `üî• [500 INTERNAL_SERVER_ERROR] Erro interno na OpenAI\n` +
          `   üìã Motivo: ${message}\n` +
          `   üîß A√ß√£o: Tentando novamente em 5 segundos (erro tempor√°rio).`
        );
        return {
          status,
          message: 'Erro interno no servidor OpenAI',
          type: 'server_error',
          retryable: true,
          retryAfter: 5000,
        };

      case 502:
        this.logger.warn(
          `üåê [502 BAD_GATEWAY] Gateway inv√°lido na OpenAI\n` +
          `   üìã Motivo: Problema de infraestrutura na OpenAI\n` +
          `   üîß A√ß√£o: Tentando novamente em 5 segundos.`
        );
        return {
          status,
          message: 'Bad Gateway - OpenAI indispon√≠vel temporariamente',
          type: 'server_error',
          retryable: true,
          retryAfter: 5000,
        };

      case 503:
        this.logger.warn(
          `üîß [503 SERVICE_UNAVAILABLE] OpenAI temporariamente indispon√≠vel\n` +
          `   üìã Motivo: Servidor sobrecarregado ou em manuten√ß√£o\n` +
          `   üîß A√ß√£o: Tentando novamente em 10 segundos.`
        );
        return {
          status,
          message: 'Servi√ßo OpenAI indispon√≠vel - manuten√ß√£o ou sobrecarga',
          type: 'server_error',
          retryable: true,
          retryAfter: 10000,
        };

      case 504:
        this.logger.warn(
          `‚è±Ô∏è [504 GATEWAY_TIMEOUT] Timeout na OpenAI\n` +
          `   üìã Motivo: Requisi√ß√£o demorou muito para processar\n` +
          `   üîß A√ß√£o: Tentando novamente em 5 segundos.`
        );
        return {
          status,
          message: 'Gateway Timeout - requisi√ß√£o demorou demais',
          type: 'server_error',
          retryable: true,
          retryAfter: 5000,
        };

      default:
        this.logger.error(
          `‚ùì [${status} UNKNOWN] Erro desconhecido da OpenAI\n` +
          `   üìã Motivo: ${message}\n` +
          `   üìã Tipo: ${type}\n` +
          `   üîß A√ß√£o: ${status >= 500 ? 'Tentando novamente (erro de servidor)' : 'N√£o faz retry (erro do cliente)'}`
        );
        return {
          status,
          message,
          type,
          retryable: status >= 500,
          retryAfter: status >= 500 ? 5000 : undefined,
        };
    }
  }

  /**
   * Identifica um item filho baseado na resposta da IA
   * Retorna o nome do item filho correspondente ou null
   */
  identifyChildItem(
    aiResponse: string,
    childOptions: string[],
  ): string | null {
    const keywords = extractKeywords(aiResponse);

    // Primeiro, tentar match exato
    for (const option of childOptions) {
      if (findBestMatch(aiResponse, [option])) {
        return option;
      }
    }

    // Segundo, tentar match por keywords
    for (const keyword of keywords) {
      const match = findBestMatch(keyword, childOptions);
      if (match) {
        return match;
      }
    }

    // Terceiro, tentar match parcial (cont√©m)
    const normalizedResponse = normalizeForMatch(aiResponse);
    for (const option of childOptions) {
      const normalizedOption = normalizeForMatch(option);
      if (
        normalizedResponse.includes(normalizedOption) ||
        normalizedOption.includes(normalizedResponse)
      ) {
        return option;
      }
    }

    return null;
  }
}
